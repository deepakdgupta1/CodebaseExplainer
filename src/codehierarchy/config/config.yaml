system:
  max_memory_gb: 26.0
  temp_dir: ".codehierarchy/temp"
  output_dir: "output"
  checkpointing_enabled: true
  checkpoint_interval: 100

parsing:
  languages:
    - "python"
    - "typescript"
  num_workers: 6
  timeout_seconds: 60
  max_file_size_mb: 10.0
  exclude_patterns:
    - "**/node_modules/**"
    - "**/venv/**"
    - "**/__pycache__/**"
    - "**/.git/**"
    - "**/dist/**"
    - "**/build/**"
    - "**/*.min.js"
    - "**/*.test.ts"
    - "**/tests/**"

graph:
  storage_mode: "in_memory"
  cache_size_gb: 2.0
  compute_metrics: true

llm:
  model_name: "Qwen2.5-Coder-32B-Instruct.IQ4_XS.gguf"
  base_url: "http://localhost:1234/v1"
  api_key: "lm-studio"
  context_window: 32768
  batch_size: 10
  temperature: 0.2
  timeout_seconds: 300
  max_retries: 2
  # Advanced LM Studio Settings
  context_overflow_policy: "stopAtLimit"
  top_k: 40
  repeat_penalty: 1.1
  min_p: 0.05
  top_p: 0.95
  gpu_offload_ratio: 1.0
  cpu_threads: 4
  eval_batch_size: 8
  flash_attention: false
  use_mmap: true

embeddings:
  model_name: "all-mpnet-base-v2"
  dimension: 768
  batch_size: 32

search:
  default_mode: "hybrid"
  index_type: "IVF256,Flat"
  nprobe: 64
  rrf_k: 60
